{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug spectra Data Camp : clasification and regression tasks ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_filename = 'train.csv'\n",
    "target_column_name_clf = 'molecule'\n",
    "target_column_name_reg = 'concentration'\n",
    "\n",
    "labels = np.array(['A', 'B', 'Q', 'R'])\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    y_df = df[[target_column_name_clf, target_column_name_reg]]\n",
    "    X_df = df.drop([target_column_name_clf, target_column_name_reg], axis=1)\n",
    "    spectra = X_df['spectra'].values\n",
    "    spectra = np.array(\n",
    "        [np.array(dd[1:-1].split(',')).astype(float) for dd in spectra])\n",
    "    X_df['spectra'] = spectra.tolist()\n",
    "    return X_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df, y_df = read_data(train_filename)\n",
    "\n",
    "skf = ShuffleSplit(n_splits=1, test_size=0.2, random_state=57)\n",
    "\n",
    "for train_is, test_is in skf.split(y_df):\n",
    "    X_train_df = X_df.iloc[train_is].copy()\n",
    "    y_train_df = y_df.iloc[train_is].copy()\n",
    "    X_test_df = X_df.iloc[test_is].copy()\n",
    "    y_test_df = y_df.iloc[test_is].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_clf = y_train_df['molecule'].values\n",
    "y_test_clf = y_test_df['molecule'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, KernelPCA, IncrementalPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.n_components = 10 # Arack as eigen_solver then, because n_components much smaller than number_samples\n",
    "        self.n_estimators = 300\n",
    "\n",
    "    def fit(self, X, y, C):\n",
    "        self.clf = Pipeline([\n",
    "            ('kpca', KernelPCA(n_components=self.n_components, fit_inverse_transform=True, eigen_solver='arpack')),\n",
    "            ('svc', SVC(C, probability=True))\n",
    "        ])\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X, surestimate):\n",
    "        prediction = self.clf.predict_proba(X)\n",
    "        prediction[:,1] *= surestimate # Error on B predominant over the rest\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KPCA is useful in our case to project the data in a space that make possible to separate them linearly.\n",
    "The idea here is to drastically decrease the number of components for the KPCA.\n",
    "It can be explained by the fact that we are keeping only fiew intensities from each spectra : the ones with the hightest variance.\n",
    "Furthermore, we use arpack as eigensolver because the compononents number is much smaller than the number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chose the SVC over the random forest classifier by testing, and set the probability mode to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = 0.015\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAJZCAYAAABvKmmyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCtlES5IkSYVsoiVJkqRC/wf8fLOWzAwHcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x165828fdeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_array_clf = np.array([np.array(dd) for dd in X_train_df['spectra']])\n",
    "X_test_array_clf = np.array([np.array(dd) for dd in X_test_df['spectra']])\n",
    "\n",
    "\"\"\"fe_clf = feature_extractor_clf.FeatureExtractorClf()\n",
    "X_train_array_clf = fe_clf.transform(X_train_df)\n",
    "X_test_array_clf = fe_clf.transform(X_test_df)\"\"\"\n",
    "\n",
    "clf = Classifier()\n",
    "plt.rcParams['figure.figsize'] = (12.0, 10.0)\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    clf.fit(X_train_array_clf, y_train_clf, C=10 ** (i+4))\n",
    "    y_proba_clf = clf.predict_proba(X_test_array_clf, 1.42)\n",
    "    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]\n",
    "    plt.scatter(np.arange(len(y_pred_clf)), y_pred_clf==y_test_clf)\n",
    "    plt.title('Predictions for SVC with C = 1e%d : error = %.2f' % (int(i+3), 1 - accuracy_score(y_test_clf, y_pred_clf)), fontsize = 12)\n",
    "\n",
    "error = 1 - accuracy_score(y_test_clf, y_pred_clf)\n",
    "print('error = %s' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note here that a huge value of C as penalization for the support vector algorithm decreases the errors.\n",
    "Furthermore, we observe there are not located at a specific area.\n",
    "I will try to determine which errors are predominant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: A\tTrue label: B\n",
      "Prediction: A\tTrue label: B\n",
      "Prediction: A\tTrue label: B\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test_clf)):\n",
    "    if y_test_clf[i] != y_pred_clf[i]:\n",
    "        print(\"Prediction: \" + y_test_clf[i] + \"\\tTrue label: \" + y_pred_clf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's note here that many errors are based on the molecule B, the next idea is to surestimate the probability associated to B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error without surestimation =  0.043\n",
      "Error with surestimation =  0.0385\n"
     ]
    }
   ],
   "source": [
    "skf = ShuffleSplit(n_splits=10, test_size=0.2, random_state=57)\n",
    "compt = 0\n",
    "errorsum1 = 0\n",
    "errorsum2 = 0\n",
    "\n",
    "for train_is, test_is in skf.split(y_df):\n",
    "    compt += 1\n",
    "    X_train_df = X_df.iloc[train_is].copy()\n",
    "    y_train_df = y_df.iloc[train_is].copy()\n",
    "    X_test_df = X_df.iloc[test_is].copy()\n",
    "    y_test_df = y_df.iloc[test_is].copy()\n",
    "    \n",
    "    y_train_clf = y_train_df['molecule'].values\n",
    "    y_test_clf = y_test_df['molecule'].values\n",
    "    \n",
    "    X_train_array_clf = np.array([np.array(dd) for dd in X_train_df['spectra']])\n",
    "    X_test_array_clf = np.array([np.array(dd) for dd in X_test_df['spectra']])\n",
    "\n",
    "    for i in range(2):\n",
    "        clf.fit(X_train_array_clf, y_train_clf, C=10 ** 5)\n",
    "        if i==0:\n",
    "            y_proba_clf = clf.predict_proba(X_test_array_clf, 1)\n",
    "        else:\n",
    "            y_proba_clf = clf.predict_proba(X_test_array_clf, 1.42)\n",
    "        y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]\n",
    "        if i == 0:\n",
    "            error1 = 1 - accuracy_score(y_test_clf, y_pred_clf)\n",
    "            errorsum1 += error1\n",
    "        else:\n",
    "            error2 = 1 - accuracy_score(y_test_clf, y_pred_clf)\n",
    "            errorsum2 += error2\n",
    "        \n",
    "print('Error without surestimation = ', errorsum1/compt)\n",
    "print('Error with surestimation = ', errorsum2/compt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that, as a average score for 10 splits on the model validation, the error is smaller when we surestimate the probabilities for B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Regression**\n",
    "\n",
    "I that the vial and solute features were pointless both for classification and for regression. This way I was able to eliminate these features from any later reasoning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.array(['A', 'B', 'Q', 'R'])\n",
    "\n",
    "class FeatureExtractorReg():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        XX = np.array([np.array(dd) for dd in X_df['spectra']])\n",
    "        \n",
    "        XX_max = np.max(XX, axis=1)\n",
    "        \n",
    "        XX -= np.mean(XX, axis=1)[:, None]\n",
    "        XX /= np.sqrt(np.sum(XX ** 2, axis=1))[:, None]\n",
    "        \n",
    "        XX = np.c_[XX, XX_max, X_df[labels].values]\n",
    "        \n",
    "        return XX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.pipeline import Pipeline                                            \n",
    "from sklearn.base import BaseEstimator\n",
    "  \n",
    "concentration = {'A': [300, 400, 600, 800, 1000, 1400, 1600, 2000, 5000, 10000],\n",
    "                 'B': [500, 1000, 1500, 2000, 4000, 5000, 7000, 10000, 20000, 25000],\n",
    "                 'Q': [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000],\n",
    "                 'R': [400, 800, 1000, 1200, 1600, 2000, 3000, 4000, 5000, 10000]\n",
    "                }\n",
    "                                              \n",
    "class Regressor(BaseEstimator):                          \n",
    "    def __init__(self):                                                          \n",
    "        self.n_components = 9\n",
    "        self.n_estimators = 1500\n",
    "        self.learning_rate = 0.2                                            \n",
    "        self.list_molecule = ['A', 'B', 'Q', 'R']                      \n",
    "        self.dict_reg = {}                                                       \n",
    "        for mol in self.list_molecule:                                           \n",
    "            self.dict_reg[mol] = Pipeline([\n",
    "                ('kpca', KernelPCA(n_components=self.n_components, fit_inverse_transform=True, eigen_solver='arpack')),                \n",
    "                ('reg', GradientBoostingRegressor(loss='huber', learning_rate=0.02, n_estimators=self.n_estimators, subsample=0.35, random_state=42, alpha=0.95))\n",
    "            ])                                                                   \n",
    "                                                                                 \n",
    "    def fit(self, X, y):                                                         \n",
    "        for i, mol in enumerate(self.list_molecule):                             \n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]             \n",
    "            XX_mol = X[ind_mol]                                                  \n",
    "            y_mol = y[ind_mol].astype(float)                                \n",
    "            self.dict_reg[mol].fit(XX_mol, np.log(y_mol))                        \n",
    "                                                                                 \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])                                            \n",
    "        for i, mol in enumerate(self.list_molecule):                             \n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]             \n",
    "            XX_mol = X[ind_mol].astype(float)                                    \n",
    "            y_pred[ind_mol] = np.exp(self.dict_reg[mol].predict(XX_mol))\n",
    "                        \n",
    "            vector_concentration = np.zeros(y_pred[ind_mol].shape) \n",
    "            for j, predict_conc in enumerate(y_pred[ind_mol]):\n",
    "                indice = np.argmin(np.abs(np.ones(len(concentration[mol]))*predict_conc - np.asarray(concentration[mol])))\n",
    "                vector_concentration[j] = concentration[mol][indice]\n",
    "\n",
    "            y_pred[ind_mol] = vector_concentration\n",
    "            \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file ...\n",
      "Training file ...\n",
      "--------------------------\n",
      "mare =  0.0857142857143\n",
      "--------------------------\n",
      "mare =  0.0861964285714\n",
      "--------------------------\n",
      "mare =  0.085005952381\n",
      "--------------------------\n",
      "mare =  0.107148809524\n",
      "--------------------------\n",
      "mare =  0.113266666667\n",
      "--------------------------\n",
      "mare =  0.107392857143\n",
      "--------------------------\n",
      "mare =  0.139642857143\n",
      "--------------------------\n",
      "mare =  0.0848154761905\n",
      "--------------------------\n",
      "mare =  0.0864722222222\n",
      "--------------------------\n",
      "mare =  0.101345238095\n",
      "--------------------------\n",
      "mean mare =  0.0997000793651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "train_filename = 'train.csv'\n",
    "target_column_name_clf = 'molecule'\n",
    "target_column_name_reg = 'concentration'\n",
    "\n",
    "labels = np.array(['A', 'B', 'Q', 'R'])\n",
    "\n",
    "\n",
    "def mare_score(y_true, y_pred):       \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    y_df = df[[target_column_name_clf, target_column_name_reg]]\n",
    "    X_df = df.drop([target_column_name_clf, target_column_name_reg], axis=1)\n",
    "    spectra = X_df['spectra'].values\n",
    "    spectra = np.array(\n",
    "        [np.array(dd[1:-1].split(',')).astype(float) for dd in spectra])\n",
    "    X_df['spectra'] = spectra.tolist()\n",
    "    return X_df, y_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    maremoy = 0\n",
    "    cpt = 0\n",
    "    print(\"Reading file ...\")\n",
    "    X_df, y_df = read_data(train_filename)\n",
    "    skf = ShuffleSplit(n_splits=10, test_size=0.2, random_state=57)\n",
    "    print(\"Training file ...\")\n",
    "    for train_is, test_is in skf.split(y_df):\n",
    "        print('--------------------------')\n",
    "        X_train_df = X_df.iloc[train_is].copy()\n",
    "        y_train_df = y_df.iloc[train_is].copy()\n",
    "        X_test_df = X_df.iloc[test_is].copy()\n",
    "        y_test_df = y_df.iloc[test_is].copy()\n",
    "        y_train_clf = y_train_df['molecule'].values\n",
    "        y_train_reg = y_train_df['concentration'].values\n",
    "        y_test_clf = y_test_df['molecule'].values\n",
    "        y_test_reg = y_test_df['concentration'].values\n",
    "        \n",
    "        X_train_array_clf = np.array([np.array(dd) for dd in X_train_df['spectra']])\n",
    "        X_test_array_clf = np.array([np.array(dd) for dd in X_test_df['spectra']])\n",
    "\n",
    "        clf = Classifier()\n",
    "        clf.fit(X_train_array_clf, y_train_clf,1e6)\n",
    "        y_proba_clf = clf.predict_proba(X_test_array_clf,1.42)\n",
    "        y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]\n",
    "        error = 1 - accuracy_score(y_test_clf, y_pred_clf)\n",
    "       \n",
    "        \n",
    "        fe_reg = FeatureExtractorReg()\n",
    "        for i, label in enumerate(labels):\n",
    "            X_train_df.loc[:, label] = (y_train_df['molecule'] == label)\n",
    "            X_test_df.loc[:, label] = y_proba_clf[:, i]\n",
    "        fe_reg.fit(X_train_df, y_train_reg)\n",
    "        X_train_array_reg = fe_reg.transform(X_train_df)\n",
    "        X_test_array_reg = fe_reg.transform(X_test_df)\n",
    "\n",
    "        reg = Regressor()\n",
    "        reg.fit(X_train_array_reg, y_train_reg)\n",
    "        y_pred_reg = reg.predict(X_test_array_reg)\n",
    "        mare = mare_score(y_test_reg, y_pred_reg)\n",
    "        print('mare = ', mare)\n",
    "        maremoy += mare\n",
    "        cpt += 1\n",
    "        \n",
    "print('--------------------------')    \n",
    "print('mean mare = ', maremoy/cpt)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above the final mean error I got here for the regression for a split of 10 iterations, which is about 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I put below key points that allowed me to discrease my error for the regression.\n",
    "Code samples may be inappropriate, it's just for giving my ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Key points leading to a minimisation of my error for the regression task:\n",
    "\n",
    "# 1st point : the first idea was to change for another model but it didn't perform better than the gradient boosting\n",
    "# I also tried to combine several models through a pipe and pick the average value predicted, but it didn't perform\n",
    "# better neither.\n",
    "# So I decided to optimize the parameters of the gradient boosting by performing a radom gridsearchCV\n",
    "# in order to converge to better parameters, and it was effective.\n",
    "\n",
    "model_old = GradientBoostingRegressor(\n",
    "                    n_estimators=30, learning_rate=0.1, random_state=42)\n",
    "\n",
    "model_new = GradientBoostingRegressor(\n",
    "                    loss='huber', learning_rate=0.02, n_estimators=1500, \n",
    "                    subsample=0.35, random_state=42, alpha=0.95)\n",
    "\n",
    "\n",
    "# 2nd point: I replaced the normalization by changing the median by the mean, which seemed more logical to me.\n",
    "# Indeed, a mean is more stable to identifiate a concentration according to the plots of the starting kit. \n",
    "# Thus, I think the distance to the mean is a better way to distinguish different concentrations than the median.\n",
    "\n",
    "# old version\n",
    "XX = [np.arange(1,10)] # just an example to make it compilable\n",
    "XX = XX - np.median(XX, axis=1)[:, None]\n",
    "# new version\n",
    "XX = XX - np.mean(XX, axis=1)[:, None]\n",
    "\n",
    "\n",
    "# 3rd point: Visualing the plots, I make the assumption that the maximum of the intensities could be useful as\n",
    "# new feature to distinguish different concentrations. Thus, I computed it and added it as a transformation.\n",
    "\n",
    "XX_max = np.max(XX, axis=1)\n",
    "## Adding this new feature to XX:\n",
    "XX = np.c_[XX, XX_max] # and concatenate the labels..\n",
    "\n",
    "\n",
    "# 4th point: According to the starting kit notebook, I saw there were only 10 different possible concentration \n",
    "# values for each molecule. So, I though I would minimize the error by keeping one on these values, the closest,\n",
    "# from my predicted concentrations. Doing that, I guarantee a error to 0 when my prediction is correct.For this \n",
    "# task I created a fixed and constant dictionary to keep in memory the possible concentration for each molecule. \n",
    "\n",
    "\n",
    "## Dictionary of concentrations per molecule\n",
    "concentration = {'A': [300, 400, 600, 800, 1000, 1400, 1600, 2000, 5000, 10000],\n",
    "                 'B': [500, 1000, 1500, 2000, 4000, 5000, 7000, 10000, 20000, 25000],\n",
    "                 'Q': [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000],\n",
    "                 'R': [400, 800, 1000, 1200, 1600, 2000, 3000, 4000, 5000, 10000]\n",
    "                }\n",
    "\n",
    "class DisplayKeyCode(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.list_molecule = ['A', 'B', 'Q', 'R']\n",
    "        self.dict_reg2 = {}\n",
    "        self.learning_rate = 0 # just an example to make it compilable\n",
    "        self.n_estimators = 0\n",
    "        \n",
    "    def predict(self, X):\n",
    "            y_pred = np.zeros(X.shape[0])                                       \n",
    "            for i, mol in enumerate(self.list_molecule):                             \n",
    "                ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]             \n",
    "                XX_mol = X[ind_mol].astype(float)                                      \n",
    "                y_pred[ind_mol] = self.transformBackY(self.dict_reg2[mol].predict(XX_mol))\n",
    "            \n",
    "                ## code improvement:\n",
    "                vector_concentration = np.zeros(y_pred[ind_mol].shape) \n",
    "                for j, predict_conc in enumerate(y_pred[ind_mol]):\n",
    "                    indice = np.argmin(np.abs(np.ones(len(concentration[mol]))*predict_conc - np.asarray(concentration[mol])))\n",
    "                    vector_concentration[j] = concentration[mol][indice]\n",
    "                y_pred[ind_mol] = vector_concentration\n",
    "                ##\n",
    "            \n",
    "            return y_pred"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
